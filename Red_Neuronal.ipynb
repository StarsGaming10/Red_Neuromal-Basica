{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPYWa4MLn12-",
        "outputId": "5ff087af-5fd0-4f5a-a6f4-bbc5aba77937"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.14.0)\n"
          ]
        }
      ],
      "source": [
        "! pip install keras"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Delaracion e inicialiazacion de la red neuronal"
      ],
      "metadata": {
        "id": "gbL-kgAXp7Y8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential as seq\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D as maxpool\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "\n",
        "#Inicializar NN\n",
        "classifier = seq()"
      ],
      "metadata": {
        "id": "bHXNT0t2uVJW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.add(Conv2D(\n",
        "      32, #cantidad de filtros que se van a a apliacar a la imagen\n",
        "      (3,3), #Tamano del filtro de convulacion\n",
        "      input_shape=(64,64,3), #Tama√±o de la imganen que va a aceptar, y que canales de color va a usar la entrada\n",
        "      activation='relu'))"
      ],
      "metadata": {
        "id": "APWE53p0qGaU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.add(maxpool(pool_size=(2,3)))"
      ],
      "metadata": {
        "id": "7Lw8u-Miunv_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.add(Flatten())"
      ],
      "metadata": {
        "id": "WQZUhISau2zJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.add(Dense(\n",
        "        units=128, #Cantidad de neuronas en la capa\n",
        "        activation='relu'\n",
        "))\n",
        "\n",
        "classifier.add(Dense(units=1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "Yng1QpP3u7XX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compilacion de la CNN"
      ],
      "metadata": {
        "id": "Yp17rGMsvl_h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.compile(optimizer='adam',\n",
        "                   loss = 'binary_crossentropy',\n",
        "                   metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "GaJj-M_cxIMj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzPOcm2Rx6z4",
        "outputId": "9b16278a-224f-4e6e-95f7-5451e2bb96d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ajustar entradas de la CNN"
      ],
      "metadata": {
        "id": "ysk3Pzmjy6AB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator as idg\n",
        "\n",
        "train_datagen = idg(rescale= 1./255)\n",
        "\n",
        "test_datagen = idg(rescale = 1./255)\n",
        "\n",
        "training_set = train_datagen.flow_from_directory('/content/drive/MyDrive/training_set_small',\n",
        "                                                target_size = (64,64),\n",
        "                                                batch_size = 1,\n",
        "                                                class_mode = 'binary')\n",
        "\n",
        "testing_set = test_datagen.flow_from_directory('/content/drive/MyDrive/test_set_small',\n",
        "                                                target_size = (64,64),\n",
        "                                                batch_size = 1,\n",
        "                                                class_mode = 'binary')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWykK3Jvy8rc",
        "outputId": "6037c4ac-eec5-4a9f-8402-c42d3c1fd72d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 600 images belonging to 2 classes.\n",
            "Found 150 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Entrenar Red\n",
        "classifier.fit(training_set, #set de entrenamiento\n",
        "               steps_per_epoch = len(training_set), #cantidad de imagenes por ciclo\n",
        "               epochs = 25, #numero de cilos o epocas de entrenamiento\n",
        "               validation_data = testing_set,\n",
        "               validation_steps = len(testing_set))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VqqVKjsc5iXx",
        "outputId": "e46073c3-cec0-4802-9ddd-f85e6b02e8ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "600/600 [==============================] - 93s 137ms/step - loss: 0.7563 - accuracy: 0.5317 - val_loss: 0.6785 - val_accuracy: 0.6333\n",
            "Epoch 2/25\n",
            "600/600 [==============================] - 4s 6ms/step - loss: 0.6318 - accuracy: 0.6650 - val_loss: 0.6019 - val_accuracy: 0.7200\n",
            "Epoch 3/25\n",
            "600/600 [==============================] - 4s 7ms/step - loss: 0.4601 - accuracy: 0.7950 - val_loss: 0.5920 - val_accuracy: 0.6533\n",
            "Epoch 4/25\n",
            "600/600 [==============================] - 6s 10ms/step - loss: 0.2728 - accuracy: 0.8883 - val_loss: 0.7316 - val_accuracy: 0.6933\n",
            "Epoch 5/25\n",
            "600/600 [==============================] - 4s 7ms/step - loss: 0.1474 - accuracy: 0.9400 - val_loss: 1.4221 - val_accuracy: 0.5400\n",
            "Epoch 6/25\n",
            "600/600 [==============================] - 4s 7ms/step - loss: 0.0798 - accuracy: 0.9783 - val_loss: 0.9689 - val_accuracy: 0.6600\n",
            "Epoch 7/25\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0321 - accuracy: 0.9950 - val_loss: 1.2656 - val_accuracy: 0.6800\n",
            "Epoch 8/25\n",
            "600/600 [==============================] - 6s 9ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 1.4066 - val_accuracy: 0.6467\n",
            "Epoch 9/25\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0104 - accuracy: 0.9983 - val_loss: 1.5332 - val_accuracy: 0.6267\n",
            "Epoch 10/25\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0878 - accuracy: 0.9817 - val_loss: 1.3087 - val_accuracy: 0.6333\n",
            "Epoch 11/25\n",
            "600/600 [==============================] - 4s 7ms/step - loss: 0.0157 - accuracy: 0.9983 - val_loss: 1.7232 - val_accuracy: 0.6133\n",
            "Epoch 12/25\n",
            "600/600 [==============================] - 4s 7ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.7650 - val_accuracy: 0.6200\n",
            "Epoch 13/25\n",
            "600/600 [==============================] - 6s 9ms/step - loss: 5.6143e-04 - accuracy: 1.0000 - val_loss: 1.9573 - val_accuracy: 0.6200\n",
            "Epoch 14/25\n",
            "600/600 [==============================] - 4s 7ms/step - loss: 2.7107e-04 - accuracy: 1.0000 - val_loss: 2.0034 - val_accuracy: 0.6067\n",
            "Epoch 15/25\n",
            "600/600 [==============================] - 6s 10ms/step - loss: 1.6724e-04 - accuracy: 1.0000 - val_loss: 1.9927 - val_accuracy: 0.6400\n",
            "Epoch 16/25\n",
            "600/600 [==============================] - 4s 7ms/step - loss: 1.1478e-04 - accuracy: 1.0000 - val_loss: 2.0515 - val_accuracy: 0.6400\n",
            "Epoch 17/25\n",
            "600/600 [==============================] - 5s 9ms/step - loss: 7.9957e-05 - accuracy: 1.0000 - val_loss: 2.1239 - val_accuracy: 0.6200\n",
            "Epoch 18/25\n",
            "600/600 [==============================] - 4s 6ms/step - loss: 5.6562e-05 - accuracy: 1.0000 - val_loss: 2.1804 - val_accuracy: 0.6267\n",
            "Epoch 19/25\n",
            "600/600 [==============================] - 6s 10ms/step - loss: 3.9409e-05 - accuracy: 1.0000 - val_loss: 2.2314 - val_accuracy: 0.6267\n",
            "Epoch 20/25\n",
            "600/600 [==============================] - 4s 7ms/step - loss: 2.8357e-05 - accuracy: 1.0000 - val_loss: 2.2323 - val_accuracy: 0.6400\n",
            "Epoch 21/25\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 2.0286e-05 - accuracy: 1.0000 - val_loss: 2.2706 - val_accuracy: 0.6400\n",
            "Epoch 22/25\n",
            "600/600 [==============================] - 5s 9ms/step - loss: 1.4754e-05 - accuracy: 1.0000 - val_loss: 2.3421 - val_accuracy: 0.6400\n",
            "Epoch 23/25\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 1.0144e-05 - accuracy: 1.0000 - val_loss: 2.3370 - val_accuracy: 0.6200\n",
            "Epoch 24/25\n",
            "600/600 [==============================] - 4s 7ms/step - loss: 7.7404e-06 - accuracy: 1.0000 - val_loss: 2.4499 - val_accuracy: 0.6333\n",
            "Epoch 25/25\n",
            "600/600 [==============================] - 4s 7ms/step - loss: 5.3460e-06 - accuracy: 1.0000 - val_loss: 2.4634 - val_accuracy: 0.6400\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7eb944d87b80>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.save('/content/drive/MyDrive/modelo.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JdN5KqOH_cv6",
        "outputId": "9187bce6-fe1c-4f98-be2b-63a98f64d0d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "classifier = load_model('/content/drive/MyDrive/modelo.h5')"
      ],
      "metadata": {
        "id": "8nS4sauS7DBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "val_image = image.load_img('/content/drive/MyDrive/single_prediction/tizo.jpg',\n",
        "                          target_size=(64,64))\n",
        "\n",
        "val_image = image.img_to_array(val_image)\n",
        "\n",
        "val_image = np.expand_dims(val_image,axis=0)\n",
        "\n",
        "result = classifier.predict(val_image)\n",
        "\n",
        "if result[0][0] == 1:\n",
        "  prediction = 'perro'\n",
        "else:\n",
        "  prediction = 'gato'\n",
        "\n",
        "print(prediction)"
      ],
      "metadata": {
        "id": "Cb0EFW06AN-2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}